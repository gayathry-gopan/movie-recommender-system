{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sXmrAvV_6I36"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import zipfile\n",
        "import urllib.request\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_URL = \"https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\"\n",
        "DATASET_ZIP = \"ml-latest-small.zip\"\n",
        "DATASET_DIR = \"ml-latest-small\""
      ],
      "metadata": {
        "id": "Qo3yqFzS9ZBM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(DATASET_ZIP):\n",
        "    urllib.request.urlretrieve(DATASET_URL, DATASET_ZIP)\n",
        "if not os.path.exists(DATASET_DIR):\n",
        "    with zipfile.ZipFile(DATASET_ZIP, 'r') as zip_ref:\n",
        "        zip_ref.extractall(\".\")"
      ],
      "metadata": {
        "id": "UcUby9FY9wDs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies = pd.read_csv(f\"{DATASET_DIR}/movies.csv\")"
      ],
      "metadata": {
        "id": "_qnpxROZ9hFj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies['content_soup'] = movies['genres'].apply(lambda x: ' '.join(x.lower().replace('-', '').split('|')))\n"
      ],
      "metadata": {
        "id": "siSICTlF9skU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(movies['content_soup'])"
      ],
      "metadata": {
        "id": "y84nN9b598fj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)"
      ],
      "metadata": {
        "id": "dO87pS6D-3wb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indices = pd.Series(movies.index, index=movies['title']).drop_duplicates()"
      ],
      "metadata": {
        "id": "QOq6sPEG_ExE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_recommendations(title, top_n=5):\n",
        "    \"\"\"\n",
        "    Given a movie title, return the top_n most similar movies (excluding itself).\n",
        "    \"\"\"\n",
        "    if title not in indices:\n",
        "        return f\"Movie '{title}' not found in database.\"\n",
        "    idx = indices[title]\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:top_n+1]  # skip itself (first item)\n",
        "    movie_indices = [i[0] for i in sim_scores]\n",
        "    return movies[['title', 'genres']].iloc[movie_indices]"
      ],
      "metadata": {
        "id": "_gaPmZbU_IbE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Top 5 movies similar to 'Toy Story (1995)':\")\n",
        "print(get_recommendations('Toy Story (1995)'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JNbmMpe_Kps",
        "outputId": "1d9eb933-2106-474b-a952-432568fa4fe5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 movies similar to 'Toy Story (1995)':\n",
            "                                               title  \\\n",
            "1706                                     Antz (1998)   \n",
            "2355                              Toy Story 2 (1999)   \n",
            "2809  Adventures of Rocky and Bullwinkle, The (2000)   \n",
            "3000                Emperor's New Groove, The (2000)   \n",
            "3568                           Monsters, Inc. (2001)   \n",
            "\n",
            "                                           genres  \n",
            "1706  Adventure|Animation|Children|Comedy|Fantasy  \n",
            "2355  Adventure|Animation|Children|Comedy|Fantasy  \n",
            "2809  Adventure|Animation|Children|Comedy|Fantasy  \n",
            "3000  Adventure|Animation|Children|Comedy|Fantasy  \n",
            "3568  Adventure|Animation|Children|Comedy|Fantasy  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A major limitation of a purely content-based recommendation system is that it can only suggest items similar to those a user has already interacted with, based on item features. This means it may fail to capture broader user preferences and cannot leverage the experiences or preferences of other users. As a result, users may miss out on discovering diverse or surprising content that they actually might get enjoy."
      ],
      "metadata": {
        "id": "XaqG0LG__z9r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Collaborative Filtering Recommender"
      ],
      "metadata": {
        "id": "fYLnqyGZBBdU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Download/load MovieLens\n",
        "import os\n",
        "import zipfile\n",
        "import urllib.request\n",
        "import pandas as pd\n",
        "\n",
        "DATASET_URL = \"https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\"\n",
        "DATASET_ZIP = \"ml-latest-small.zip\"\n",
        "DATASET_DIR = \"ml-latest-small\"\n",
        "\n",
        "if not os.path.exists(DATASET_ZIP):\n",
        "    urllib.request.urlretrieve(DATASET_URL, DATASET_ZIP)\n",
        "if not os.path.exists(DATASET_DIR):\n",
        "    with zipfile.ZipFile(DATASET_ZIP, 'r') as zip_ref:\n",
        "        zip_ref.extractall(\".\")\n",
        "\n",
        "ratings = pd.read_csv(f\"{DATASET_DIR}/ratings.csv\")\n",
        "movies = pd.read_csv(f\"{DATASET_DIR}/movies.csv\")\n",
        "\n",
        "# 2. Create user-item matrix\n",
        "user_item_matrix = ratings.pivot(index='userId', columns='movieId', values='rating').fillna(0)\n",
        "print(\"Matrix shape:\", user_item_matrix.shape)\n",
        "\n",
        "# 3. Compute SVD using numpy/scipy\n",
        "from scipy.sparse.linalg import svds\n",
        "import numpy as np\n",
        "\n",
        "user_ratings_mean = np.mean(user_item_matrix.values, axis=1)\n",
        "R_demeaned = user_item_matrix.values - user_ratings_mean.reshape(-1, 1)\n",
        "\n",
        "# Compute SVD\n",
        "U, sigma, VT = svds(R_demeaned, k=20)\n",
        "sigma = np.diag(sigma)\n",
        "\n",
        "\n",
        "predicted_ratings = np.dot(np.dot(U, sigma), VT) + user_ratings_mean.reshape(-1, 1)\n",
        "predicted_ratings_df = pd.DataFrame(predicted_ratings, index=user_item_matrix.index, columns=user_item_matrix.columns)\n",
        "\n",
        "#  Recommend top-5 movies for a user\n",
        "def recommend_movies(pred_ratings_df, original_ratings, movies_df, user_id, n=5):\n",
        "    user_row = pred_ratings_df.loc[user_id]\n",
        "    # Movies the user has already rated\n",
        "    rated_movies = set(original_ratings[original_ratings['userId']==user_id]['movieId'])\n",
        "    # Recommend movies not yet rated\n",
        "    recommendations = user_row.drop(labels=rated_movies).sort_values(ascending=False).head(n)\n",
        "    return movies_df[movies_df['movieId'].isin(recommendations.index)][['movieId','title']]\n",
        "\n",
        "print(\"\\nTop 5 recommendations for user 1:\")\n",
        "print(recommend_movies(predicted_ratings_df, ratings, movies, user_id=1, n=5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdPhS_cpFFGe",
        "outputId": "710b709b-4e96-46b5-d5fd-ea01b7ee56ee"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix shape: (610, 9724)\n",
            "\n",
            "Top 5 recommendations for user 1:\n",
            "      movieId                              title\n",
            "507       589  Terminator 2: Judgment Day (1991)\n",
            "793      1036                    Die Hard (1988)\n",
            "902      1200                      Aliens (1986)\n",
            "1445     1968         Breakfast Club, The (1985)\n",
            "2078     2762            Sixth Sense, The (1999)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A collaborative filtering model like SVD assumes that users who have shown similar preferences in the past will continue to have similar tastes in the future."
      ],
      "metadata": {
        "id": "4gPw7N41F8tG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Conceptual Analysis"
      ],
      "metadata": {
        "id": "G08uLAtbG4S9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The Cold Start Problem in Recommender Systems\n",
        "\n",
        "The \"cold start problem\" is the difficulty that the recommender system faces when they have to make recommendations involving new users or new items (such as movies) for which there is little or no historical data.\n",
        "\n",
        "#### New User Cold Start\n",
        "When a new user joins the platform, the system has no information about their preferences or past ratings. This makes it challenging for collaborative filtering models, which rely on user interaction data to find similar users and make predictions.\n",
        "\n",
        "- Content-Based Model: Handles the new user cold start better if the user provides some initial preferences (e.g., selecting favorite genres or keywords), as recommendations can be made immediately based on item attributes.\n",
        "- Collaborative Filtering Model (e.g., SVD): Performs poorly in this scenario because it needs user-item interaction data to generate recommendations.\n",
        "\n",
        "#### New Movie Cold Start\n",
        "When a new movie is added, there are no user ratings or interactions for that movie.\n",
        "\n",
        "- Content-Based Model: Handles the new movie cold start well, as it can recommend the new movie to users if its content (e.g., genres, description) matches their profiles, even without any user ratings.\n",
        "- Collaborative Filtering Model: Struggles with new movies, since it canâ€™t recommend items that have no ratings or interaction history.\n"
      ],
      "metadata": {
        "id": "qAXqAmTHG581"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pickle\n",
        "\n",
        "with open('content_model.pkl', 'wb') as f:\n",
        "    pickle.dump({\n",
        "        'tfidf': tfidf,\n",
        "        'cosine_sim': cosine_sim,\n",
        "        'movies': movies\n",
        "    }, f)\n",
        "\n",
        "with open('cf_model.pkl', 'wb') as f:\n",
        "    pickle.dump({\n",
        "        'predicted_ratings_df': predicted_ratings_df,\n",
        "        'movies': movies\n",
        "    }, f)"
      ],
      "metadata": {
        "id": "a8V3HE7dKyVv"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('content_model.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "h5aEUXa0NCot",
        "outputId": "e367832f-40d7-4214-a335-0237871b412e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_623a8f5a-c528-4720-8596-ba20957e5754\", \"content_model.pkl\", 759687286)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JD-bUb2aHuhd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}