{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 1. Uninstall NumPy and related packages\n",
        "!pip uninstall -y numpy pandas scikit-surprise\n",
        "\n",
        "# 2. Install compatible versions\n",
        "!pip install numpy==1.26.4 pandas scikit-surprise\n",
        "\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iI05umiO_U4",
        "outputId": "e9757f4c-2e97-4363-b897-45ca7b5ad685"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 1.26.4\n",
            "Uninstalling numpy-1.26.4:\n",
            "  Successfully uninstalled numpy-1.26.4\n",
            "Found existing installation: pandas 2.2.2\n",
            "Uninstalling pandas-2.2.2:\n",
            "  Successfully uninstalled pandas-2.2.2\n",
            "Found existing installation: scikit-surprise 1.1.4\n",
            "Uninstalling scikit-surprise-1.1.4:\n",
            "  Successfully uninstalled scikit-surprise-1.1.4\n",
            "Collecting numpy==1.26.4\n",
            "  Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting pandas\n",
            "  Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-surprise\n",
            "  Using cached scikit_surprise-1.1.4-cp312-cp312-linux_x86_64.whl\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-surprise) (1.5.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-surprise) (1.16.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m121.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, pandas, scikit-surprise\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.3 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "dask-cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.3 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4 pandas-2.3.3 scikit-surprise-1.1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMFWTh-rOGtN",
        "outputId": "49068a84-f46c-4f84-f7d4-18a281ec5ab4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   25.7s\n",
            "[Parallel(n_jobs=-1)]: Done  81 out of  81 | elapsed:  1.2min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best RMSE score attained:  0.8636980629963467\n",
            "Best hyperparameters:  {'n_epochs': 30, 'lr_all': 0.01, 'reg_all': 0.1}\n",
            "RMSE: 0.8626\n",
            "Final Model RMSE on test set: 0.8626\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from surprise import Dataset, Reader, SVD\n",
        "from surprise.model_selection import GridSearchCV, train_test_split\n",
        "\n",
        "\n",
        "ratings_df = pd.read_csv('ratings.csv')\n",
        "\n",
        "# Step 3: Prepare the Data for Surprise\n",
        "reader = Reader(rating_scale=(ratings_df.rating.min(), ratings_df.rating.max()))\n",
        "data = Dataset.load_from_df(ratings_df[['userId', 'movieId', 'rating']], reader)\n",
        "\n",
        "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Hyperparameter Tuning with GridSearchCV\n",
        "param_grid = {\n",
        "    'n_epochs': [10, 20, 30],\n",
        "    'lr_all': [0.002, 0.005, 0.01],\n",
        "    'reg_all': [0.02, 0.05, 0.1]\n",
        "}\n",
        "\n",
        "gs = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=3, joblib_verbose=2, n_jobs=-1)\n",
        "gs.fit(data)\n",
        "\n",
        "print(\"Best RMSE score attained: \", gs.best_score['rmse'])\n",
        "print(\"Best hyperparameters: \", gs.best_params['rmse'])\n",
        "\n",
        "# Train Model with Best Hyperparameters\n",
        "best_params = gs.best_params['rmse']\n",
        "final_model = SVD(**best_params)\n",
        "final_model.fit(trainset)\n",
        "\n",
        "#Evaluate\n",
        "from surprise import accuracy\n",
        "\n",
        "predictions = final_model.test(testset)\n",
        "rmse = accuracy.rmse(predictions)\n",
        "print(f'Final Model RMSE on test set: {rmse:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameter tuning is critical before deploying a machine learning model because it helps find the best combination of settings that maximize the model's performance on your data. Using default parameters can lead to suboptimal results, that may result in poor accuracy, overfitting, or underfitting."
      ],
      "metadata": {
        "id": "TR1X-lrHQyp_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ip9n7Np1POo2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}